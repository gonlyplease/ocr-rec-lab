{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation Classification Inference\n",
    "\n",
    "This notebook performs inference on images using the trained rotation classification model.\n",
    "It processes images from a specified folder and displays results for non-zero predictions only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_PATH = \"pipeline/checkpoints/best_model.pth\"  # Path to your trained model\n",
    "IMAGE_SIZE = 300\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Class names (rotation angles)\n",
    "CLASS_NAMES = ['0', '180', '270', '90']  # Adjust based on your actual class order\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, num_classes, device):\n",
    "    \"\"\"Load the trained model from checkpoint.\"\"\"\n",
    "    model = resnet18()\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded successfully from {model_path}\")\n",
    "    print(f\"Model was trained for {checkpoint['epoch']} epochs\")\n",
    "    print(f\"Best validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load the model\n",
    "model = load_model(MODEL_PATH, len(CLASS_NAMES), DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the same preprocessing as used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess a single image for inference.\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image, image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rotation(model, image_tensor, device):\n",
    "    \"\"\"Predict rotation angle for a single image.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        outputs = model(image_tensor)\n",
    "        \n",
    "        # Get probabilities\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "        \n",
    "        return predicted.item(), confidence.item(), probabilities.squeeze().cpu().numpy()\n",
    "\n",
    "def visualize_prediction(image, image_path, predicted_class, confidence, probabilities, class_names):\n",
    "    \"\"\"Visualize the image with prediction results.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Display image\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title(f\"Image: {os.path.basename(image_path)}\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Display prediction results\n",
    "    ax2.bar(class_names, probabilities)\n",
    "    ax2.set_title(f\"Prediction: {class_names[predicted_class]}° (Confidence: {confidence:.3f})\")\n",
    "    ax2.set_ylabel('Probability')\n",
    "    ax2.set_xlabel('Rotation Angle')\n",
    "    \n",
    "    # Highlight the predicted class\n",
    "    ax2.bar(class_names[predicted_class], probabilities[predicted_class], color='red', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"File: {os.path.basename(image_path)}\")\n",
    "    print(f\"Predicted rotation: {class_names[predicted_class]}°\")\n",
    "    print(f\"Confidence: {confidence:.3f}\")\n",
    "    print(f\"All probabilities: {dict(zip(class_names, [f'{p:.3f}' for p in probabilities]))}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference on Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, model, device, class_names, show_only_non_zero=True):\n",
    "    \"\"\"Process all images in a folder and show results.\"\"\"\n",
    "    # Supported image extensions\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(folder_path, ext)))\n",
    "        image_files.extend(glob.glob(os.path.join(folder_path, ext.upper())))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No image files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images in {folder_path}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for image_path in sorted(image_files):\n",
    "        try:\n",
    "            # Preprocess image\n",
    "            image, image_tensor = preprocess_image(image_path)\n",
    "            \n",
    "            # Predict\n",
    "            predicted_class, confidence, probabilities = predict_rotation(model, image_tensor, device)\n",
    "            \n",
    "            # Store result\n",
    "            results.append({\n",
    "                'path': image_path,\n",
    "                'image': image,\n",
    "                'predicted_class': predicted_class,\n",
    "                'confidence': confidence,\n",
    "                'probabilities': probabilities\n",
    "            })\n",
    "            \n",
    "            # Show only non-zero predictions if requested\n",
    "            if show_only_non_zero and class_names[predicted_class] != '0':\n",
    "                visualize_prediction(image, image_path, predicted_class, confidence, probabilities, class_names)\n",
    "            elif not show_only_non_zero:\n",
    "                visualize_prediction(image, image_path, predicted_class, confidence, probabilities, class_names)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {str(e)}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Folder \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mINPUT_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Process all images in the folder\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_FOLDER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASS_NAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_only_non_zero\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Summary statistics\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results:\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m, in \u001b[0;36mprocess_folder\u001b[1;34m(folder_path, model, device, class_names, show_only_non_zero)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(image_files):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;66;03m# Preprocess image\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m         image, image_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         predicted_class, confidence, probabilities \u001b[38;5;241m=\u001b[39m predict_rotation(model, image_tensor, device)\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpreprocess_image\u001b[39m(image_path):\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess a single image for inference.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m transform(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image, image_tensor\n",
      "File \u001b[1;32mc:\\Users\\saschamueller\\Documents\\GitHub\\ocr-rec-lab\\venv\\lib\\site-packages\\PIL\\Image.py:3513\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_path(fp):\n\u001b[0;32m   3512\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fp)\n\u001b[1;32m-> 3513\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3514\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3515\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Update the INPUT_FOLDER path to your actual folder\n",
    "BASE_FOLDER = \"data/rotation/batches/\"\n",
    "ADDENDUM=\"/images/boxes\"\n",
    "FOLDER=\"task_lyd batch 26_backup_2025_07_18_13_47_53_COCO\"\n",
    "INPUT_FOLDER = BASE_FOLDER+FOLDER+ADDENDUM\n",
    "\n",
    "\n",
    "# Check if folder exists\n",
    "if not os.path.exists(INPUT_FOLDER):\n",
    "    print(f\"Error: Folder '{INPUT_FOLDER}' does not exist.\")\n",
    "else:\n",
    "    # Process all images in the folder\n",
    "    results = process_folder(INPUT_FOLDER, model, DEVICE, CLASS_NAMES, show_only_non_zero=True)\n",
    "    \n",
    "    # Summary statistics\n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_images = len(results)\n",
    "        class_counts = {class_name: 0 for class_name in CLASS_NAMES}\n",
    "        \n",
    "        for result in results:\n",
    "            predicted_class_name = CLASS_NAMES[result['predicted_class']]\n",
    "            class_counts[predicted_class_name] += 1\n",
    "        \n",
    "        print(f\"Total images processed: {total_images}\")\n",
    "        print(\"\\nPrediction distribution:\")\n",
    "        for class_name, count in class_counts.items():\n",
    "            percentage = (count / total_images) * 100\n",
    "            print(f\"  {class_name}°: {count} images ({percentage:.1f}%)\")\n",
    "        \n",
    "        non_zero_count = sum(count for class_name, count in class_counts.items() if class_name != '0')\n",
    "        print(f\"\\nImages requiring rotation: {non_zero_count} ({(non_zero_count/total_images)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Show All Results (including 0° predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell if you want to see ALL predictions (including 0° rotations)\n",
    "\n",
    "# show_all = input(\"Do you want to see ALL predictions including 0° rotations? (y/n): \")\n",
    "# if show_all.lower() == 'y':\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"SHOWING ALL PREDICTIONS (INCLUDING 0° ROTATIONS)\")\n",
    "#     print(\"=\" * 60)\n",
    "#     \n",
    "#     if 'results' in locals():\n",
    "#         for result in results:\n",
    "#             if CLASS_NAMES[result['predicted_class']] == '0':  # Show only 0° predictions this time\n",
    "#                 visualize_prediction(\n",
    "#                     result['image'], \n",
    "#                     result['path'], \n",
    "#                     result['predicted_class'], \n",
    "#                     result['confidence'], \n",
    "#                     result['probabilities'], \n",
    "#                     CLASS_NAMES\n",
    "#                 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
