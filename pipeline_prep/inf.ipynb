{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d87ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model from checkpoints/best_model.pth\n",
      "INFO:__main__:=== Processing rotation_20250721_01 ===\n",
      "INFO:__main__:Loading COCO from ../data/rotation/batches/rotation_20250721_01/annotations/instances_default.json\n",
      "INFO:__main__:Writing COCO to ../data/rotation/batches/rotation_20250721_01/annotations/instances_obbs.json\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Rotation Prediction Pipeline\n",
    "# This notebook implements a production-ready pipeline to process multiple batches of images stored in folders. It converts COCO annotations into oriented bounding boxes (OBB), runs a rotation prediction model on each detected object, and saves updated annotations.\n",
    "# The flow is kept similar to the original script, with core logic unchanged. Each batch directory under `BATCHES_DIR` will be processed automatically.\n",
    "\n",
    "# %%\n",
    "# ---------------------------\n",
    "# IMPORTS & CONFIGURATION\n",
    "# ---------------------------\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Setup logging\n",
    "default_level = logging.INFO\n",
    "logging.basicConfig(level=default_level)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Global configuration\n",
    "BATCHES_DIR = Path(\"../data/rotation/batches/\")\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/best_model.pth\")\n",
    "DEBUG_ROOT = Path(\"../pipeline/debug_imgs/\")\n",
    "CLASS_NAMES = [0, 180, 270, 90]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_SIZE = 300\n",
    "\n",
    "# Transform for model input\n",
    "TRANSFORM = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE), transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# %%\n",
    "# ---------------------------\n",
    "# I/O UTILITIES\n",
    "# ---------------------------\n",
    "def load_coco(path: Path) -> dict:\n",
    "    logger.info(f\"Loading COCO from {path}\")\n",
    "    return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "def save_coco(coco: dict, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"Writing COCO to {path}\")\n",
    "    path.write_text(json.dumps(coco, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# %%\n",
    "# ---------------------------\n",
    "# MODEL LOADING\n",
    "# ---------------------------\n",
    "def load_model(ckpt_path: Path) -> nn.Module:\n",
    "    logger.info(f\"Loading model from {ckpt_path}\")\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(CLASS_NAMES))\n",
    "    ckpt = torch.load(str(ckpt_path), map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"]);\n",
    "    model.to(DEVICE).eval()\n",
    "    return model\n",
    "\n",
    "# %%\n",
    "# ---------------------------\n",
    "# UTILITY FUNCTIONS\n",
    "# ---------------------------\n",
    "def create_obb_tuple(anns: dict):\n",
    "    bbox = anns.get(\"bbox\")\n",
    "    if isinstance(bbox, list) and len(bbox) == 4:\n",
    "        x, y, w, h = bbox\n",
    "        cx, cy = x + w/2, y + h/2\n",
    "        angle = anns.get(\"attributes\", {}).get(\"rotation\", 0.0)\n",
    "        anns[\"bbox\"] = [cx, cy, w, h, angle]\n",
    "    else:\n",
    "        logger.warning(f\"Unexpected bbox for ann {anns.get('id')}: {bbox}\")\n",
    "\n",
    "\n",
    "def replace_obb(coco: dict):\n",
    "    for anns in coco.get(\"annotations\", []):\n",
    "        create_obb_tuple(anns)\n",
    "    return coco\n",
    "\n",
    "\n",
    "def extract_rotation(ann: dict) -> float:\n",
    "    bb = ann.get(\"bbox\", [])\n",
    "    return float(bb[4]) if len(bb)==5 else float(ann.get(\"attributes\", {}).get(\"rotation\", 0.0))\n",
    "\n",
    "\n",
    "def crop_obb_exact_mask_trim(img: np.ndarray, cx: float, cy: float, w: float, h: float, angle: float, pad: int=0) -> np.ndarray:\n",
    "    theta = np.deg2rad(angle); ct, st = np.cos(theta), np.sin(theta)\n",
    "    local = np.float32([[-w/2,-h/2],[w/2,-h/2],[w/2,h/2],[-w/2,h/2]])\n",
    "    poly = (local @ np.float32([[ct,-st],[st,ct]]).T) + [cx, cy]\n",
    "    xs, ys = poly[:,0], poly[:,1]\n",
    "    x0, x1 = int(np.floor(xs.min()))-pad, int(np.ceil(xs.max()))+pad\n",
    "    y0, y1 = int(np.floor(ys.min()))-pad, int(np.ceil(ys.max()))+pad\n",
    "    x0, y0 = max(0,x0), max(0,y0)\n",
    "    x1, y1 = min(img.shape[1]-1,x1), min(img.shape[0]-1,y1)\n",
    "    roi = img[y0:y1+1, x0:x1+1].copy()\n",
    "    poly_roi = (poly - [x0,y0]).astype(np.int32)\n",
    "    mask = np.zeros(roi.shape[:2], np.uint8)\n",
    "    cv2.fillPoly(mask, [poly_roi], 255)\n",
    "    patch = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "    ys_nz, xs_nz = np.where(mask>0)\n",
    "    return patch[ys_nz.min():ys_nz.max()+1, xs_nz.min():xs_nz.max()+1]\n",
    "\n",
    "\n",
    "def predict_angle(model: nn.Module, patch: np.ndarray) -> float:\n",
    "    rgb = cv2.cvtColor(patch, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(rgb)\n",
    "    tensor = TRANSFORM(img).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out = model(tensor)\n",
    "        idx = torch.argmax(out, dim=1).item()\n",
    "    return float(CLASS_NAMES[idx])\n",
    "\n",
    "\n",
    "def is_valid_rotation(angle: float, tol: int=3) -> bool:\n",
    "    return any(abs(angle-base)<=tol for base in CLASS_NAMES)\n",
    "\n",
    "# %%\n",
    "# ---------------------------\n",
    "# PIPELINE: PROCESS ONE BATCH\n",
    "# ---------------------------\n",
    "def process_batch(batch_dir: Path, model: nn.Module):\n",
    "    # Paths\n",
    "    coco_in = batch_dir / \"annotations\" / \"instances_default.json\"\n",
    "    ococo = batch_dir / \"annotations\" / \"instances_obbs.json\"\n",
    "    pred_out = batch_dir / \"annotations\" / \"instances_predicted.json\"\n",
    "    imgs_dir = batch_dir / \"images\" / \"default\"\n",
    "    debug_dir = DEBUG_ROOT / batch_dir.name\n",
    "    debug_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load & convert to OBB\n",
    "    coco = load_coco(coco_in)\n",
    "    coco = replace_obb(coco)\n",
    "    save_coco(coco, ococo)\n",
    "\n",
    "    # Prepare prediction copy\n",
    "    coco_pred = deepcopy(coco)\n",
    "    images = {img['id']: img for img in coco['images']}\n",
    "    cache = {}\n",
    "    records = []\n",
    "\n",
    "    # Iterate all annotations\n",
    "    for ann, ann_pred in zip(coco['annotations'], coco_pred['annotations']):\n",
    "        cx,cy,w,h,orig = ann['bbox']\n",
    "        if not is_valid_rotation(orig):\n",
    "            continue\n",
    "        fname = images[ann['image_id']]['file_name']\n",
    "        path = imgs_dir / fname\n",
    "        if not path.exists():\n",
    "            logger.error(f\"Missing image {path}\"); continue\n",
    "        img = cache.get(fname) if fname in cache else cv2.imread(str(path))\n",
    "        cache[fname] = img\n",
    "        patch = crop_obb_exact_mask_trim(img, cx, cy, w, h, orig)\n",
    "        out_file = debug_dir / f\"{Path(fname).stem}_{ann['id']}.png\"\n",
    "        cv2.imwrite(str(out_file), patch)\n",
    "        pred = predict_angle(model, patch)\n",
    "        records.append({\"id\": ann['id'], \"orig\": orig, \"pred\": pred})\n",
    "        if pred != orig:\n",
    "            ann_pred['bbox'][4] = pred\n",
    "            ann_pred.setdefault('attributes', {})['rotation'] = pred\n",
    "    # Save predictions & summary\n",
    "    save_coco(coco_pred, pred_out)\n",
    "    df = pd.DataFrame(records)\n",
    "    df.to_csv(batch_dir / \"results.csv\", index=False)\n",
    "    logger.info(f\"Finished batch {batch_dir.name}, processed {len(records)} objects.\")\n",
    "\n",
    "# %%\n",
    "# ---------------------------\n",
    "# MAIN: LOOP ALL BATCHES\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    model = load_model(CHECKPOINT_PATH)\n",
    "    for batch in BATCHES_DIR.iterdir():\n",
    "        if batch.is_dir() and batch.name.startswith(\"rotation_\"):\n",
    "            logger.info(f\"=== Processing {batch.name} ===\")\n",
    "            process_batch(batch, model)\n",
    "    logger.info(\"All batches processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr-rec-lab-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
