{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c90357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define model architecture\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, 4)  # 4 classes: 0, 90, 180, 270\n",
    "\n",
    "# Load saved weights\n",
    "checkpoint = torch.load(\"checkpoints/best_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3612adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "CROPS_DIR = Path(\"../data/rotation/classification/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2472f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ALL_ANGLES_CROPS = Path(\"../data/rotation/classification/all_angles_from_test\")\n",
    "\n",
    "os.makedirs(\"../data/rotation/classification/all_angles_from_test\", exist_ok=True)\n",
    "\n",
    "for p in CROPS_DIR.iterdir():\n",
    "    print(p)\n",
    "    \n",
    "    for f in p.iterdir():\n",
    "        print(f.name)\n",
    "\n",
    "        shutil.move(f, ALL_ANGLES_CROPS / f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ALL_ANGLES_CROPS.iterdir():\n",
    "    print(f.name)\n",
    "    if (\"_45.png\" in f.name):\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd888d52",
   "metadata": {},
   "source": [
    "## Move crops from cad crops clean to test crops in order to test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2169c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CAD_CROPS_CLEAN = Path(\"../data/cad_crops/\")\n",
    "TEST_CROPS = Path(\"../data/test_crops\")\n",
    "\n",
    "\n",
    "for p in CAD_CROPS_CLEAN.iterdir():\n",
    "    if (\".jpg\" in p.name):\n",
    "        print(p)\n",
    "        shutil.move(p, TEST_CROPS / p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aec33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def rotate_patch(patch: np.ndarray, angle: int) -> np.ndarray:\n",
    "    h, w = patch.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w / 2, h / 2), angle, 1.0)\n",
    "    cos, sin = abs(M[0, 0]), abs(M[0, 1])\n",
    "    new_w = int(h * sin + w * cos)\n",
    "    new_h = int(h * cos + w * sin)\n",
    "    M[0, 2] += new_w / 2 - w / 2\n",
    "    M[1, 2] += new_h / 2 - h / 2\n",
    "\n",
    "    border = (0, 0, 0, 0) if patch.shape[2] == 4 else (255, 255, 255)\n",
    "    return cv2.warpAffine(\n",
    "        patch,\n",
    "        M,\n",
    "        (new_w, new_h),\n",
    "        flags=cv2.INTER_LINEAR,\n",
    "        borderMode=cv2.BORDER_CONSTANT,\n",
    "        borderValue=border\n",
    "    )\n",
    "\n",
    "# Config\n",
    "TEST_CROPS = Path(\"../data/test_crops\")\n",
    "NEW_ANGLES = [90, 180, 270]\n",
    "ANGLE_SUFFIXES = [0] + NEW_ANGLES\n",
    "VALID_EXTS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "\n",
    "def standardize_and_rotate():\n",
    "    # Step 1: count files before\n",
    "    files_before = list(TEST_CROPS.glob(\"*\"))\n",
    "    original_img_count = len([f for f in files_before if f.suffix.lower() in VALID_EXTS])\n",
    "\n",
    "    print(f\"\\nüì∏ Images before processing: {original_img_count}\")\n",
    "\n",
    "    # Process each image\n",
    "    for img_path in files_before:\n",
    "        if not img_path.is_file() or img_path.suffix.lower() not in VALID_EXTS:\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_UNCHANGED)\n",
    "        if img is None:\n",
    "            print(f\"‚ö†Ô∏è Failed to load {img_path}\")\n",
    "            continue\n",
    "\n",
    "        base_name = img_path.stem.split(\"_\")[0]\n",
    "        new_name = f\"{base_name}_0.png\"\n",
    "        new_path = TEST_CROPS / new_name\n",
    "\n",
    "        cv2.imwrite(str(new_path), img)\n",
    "        print(f\"‚úÖ Renamed/saved: {new_name}\")\n",
    "\n",
    "        for angle in NEW_ANGLES:\n",
    "            out_name = f\"{base_name}_{angle}.png\"\n",
    "            out_path = TEST_CROPS / out_name\n",
    "\n",
    "            if not out_path.exists():\n",
    "                rotated = rotate_patch(img, angle)\n",
    "                cv2.imwrite(str(out_path), rotated)\n",
    "                print(f\"üåÄ Rotated {angle}¬∞ -> {out_name}\")\n",
    "\n",
    "        # Delete old file if different from new path\n",
    "        if img_path != new_path:\n",
    "            img_path.unlink()\n",
    "\n",
    "    # Step 2: count files after\n",
    "    files_after = list(TEST_CROPS.glob(\"*.png\"))\n",
    "    final_count = len(files_after)\n",
    "\n",
    "    # Step 3: group by base name\n",
    "    base_to_angles = defaultdict(set)\n",
    "    for f in files_after:\n",
    "        parts = f.stem.split(\"_\")\n",
    "        if len(parts) == 2 and parts[1].isdigit():\n",
    "            base, angle = parts\n",
    "            base_to_angles[base].add(int(angle))\n",
    "\n",
    "    expected_total = len(base_to_angles) * 4\n",
    "    missing_images = expected_total - final_count\n",
    "\n",
    "    print(f\"\\nüßÆ Final stats:\")\n",
    "    print(f\"‚û°Ô∏è Total unique base images: {len(base_to_angles)}\")\n",
    "    print(f\"‚û°Ô∏è Expected image count (4 per base): {expected_total}\")\n",
    "    print(f\"‚úÖ Images after processing: {final_count}\")\n",
    "    print(f\"‚ùå Missing images: {missing_images}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    standardize_and_rotate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),  # Match training resolution\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2376e559",
   "metadata": {},
   "source": [
    "## Test Inference Model with rotated Data in test_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "suffix = \".png\"\n",
    "\n",
    "def predict_images():\n",
    "    CLASS_NAMES = [0, 180, 270, 90]\n",
    "\n",
    "    total_angle_off = 0\n",
    "    count = 0\n",
    "    false_pred_count = 0\n",
    "    printed_errors = 0\n",
    "    max_to_print = 30\n",
    "    logs = []\n",
    "\n",
    "    for f in TEST_CROPS.iterdir():\n",
    "        if f.suffix.lower() != suffix:\n",
    "            continue\n",
    "\n",
    "        img = Image.open(f).convert(\"RGB\")\n",
    "        input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "        pred_angle = CLASS_NAMES[predicted.item()]\n",
    "\n",
    "        try:\n",
    "            angle = int(f.stem.split(\"_\")[-1])\n",
    "        except ValueError:\n",
    "            msg = f\"‚ö†Ô∏è Could not extract angle from filename: {f.name}\"\n",
    "            print(msg)\n",
    "            logs.append(msg)\n",
    "            continue\n",
    "\n",
    "        angle_diff = (pred_angle - angle) % 360\n",
    "        angle_diff = min(angle_diff, 360 - angle_diff)\n",
    "        total_angle_off += angle_diff\n",
    "\n",
    "        correct = (angle == pred_angle)\n",
    "        if not correct:\n",
    "            false_pred_count += 1\n",
    "            msg = f\"‚ùå {f.name} | GT: {angle}¬∞, Pred: {pred_angle}¬∞\"\n",
    "            logs.append(msg)\n",
    "\n",
    "            if printed_errors < max_to_print:\n",
    "                print(msg)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"{f.name} | Predicted: {pred_angle}¬∞ | ‚úó\")\n",
    "                plt.axis(\"off\")\n",
    "                plt.show()\n",
    "                printed_errors += 1\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    summary = f\"üßÆ Total angular error: {total_angle_off}¬∞, Incorrect predictions: {false_pred_count}/{count}\"\n",
    "    print(summary)\n",
    "    logs.append(summary)\n",
    "\n",
    "    # Speichere alles in Log-Datei\n",
    "    with open(\"prediction_log.txt\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "        f_out.write(\"\\n\".join(logs))\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(predict_images())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr-rec-lab-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
