{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f90737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "\n",
    "# Configure logging for better debug information\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# CONFIGURATION\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Paths (customize these)\n",
    "COCO_JSON        = Path(\"../data/rotation/instances_unknown.json\")\n",
    "IMAGES_DIR       = Path(\"../data/rotation/images/default\")\n",
    "OUTPUT_JSON      = Path(\"../data/rotation/instances_predicted.json\")\n",
    "CHECKPOINT_PATH  = Path(\"checkpoints/best_model.pth\")\n",
    "\n",
    "# Class labels in the exact order your model was trained on\n",
    "CLASS_NAMES = [0, 90, 180, 270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f1fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Preprocessing for the classifier\n",
    "TRANSFORM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac9e0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# COCO I/O\n",
    "\n",
    "def load_coco(json_path: Path) -> dict:\n",
    "    logger.info(f\"Loading COCO annotations from {json_path}\")\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "    \n",
    "def save_coco(coco: dict, out_path: Path) -> None:\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(f\"Writing updated COCO to {out_path}\")\n",
    "    with open(out_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(coco, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5960b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# MODEL LOADING\n",
    "\n",
    "def load_model(checkpoint_path: Path) -> torch.nn.Module:\n",
    "    logger.info(f\"Loading model from {checkpoint_path}\")\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(CLASS_NAMES))\n",
    "    checkpoint = torch.load(str(checkpoint_path), map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(DEVICE).eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977597fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# CROPPING & INFERENCE\n",
    "\n",
    "def crop_box(img: np.ndarray, x: float, y: float, w: float, h: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Crop an axis-aligned box [x, y, w, h] from img.\n",
    "    \"\"\"\n",
    "    x1 = int(round(x))\n",
    "    y1 = int(round(y))\n",
    "    x2 = int(round(x + w))\n",
    "    y2 = int(round(y + h))\n",
    "    # clamp to image bounds\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2 = min(img.shape[1], x2)\n",
    "    y2 = min(img.shape[0], y2)\n",
    "    return img[y1:y2, x1:x2]\n",
    "\n",
    "\n",
    "def predict_angle(model: torch.nn.Module, patch: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Run the classifier on the BGR-uint8 patch and return one of CLASS_NAMES.\n",
    "    \"\"\"\n",
    "    # to PIL-like RGB\n",
    "    patch_rgb = cv2.cvtColor(patch, cv2.COLOR_BGR2RGB)\n",
    "    # apply transforms\n",
    "    tensor = TRANSFORM(patch_rgb).unsqueeze(0).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(tensor)\n",
    "        idx = int(logits.argmax(dim=1))\n",
    "    return CLASS_NAMES[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ebde2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNCOMMENT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  UPDATE LOOP\n",
    "\n",
    "def update_rotations():\n",
    "    coco = load_coco(COCO_JSON)\n",
    "    model = load_model(CHECKPOINT_PATH)\n",
    "\n",
    "    # build lookup for images\n",
    "    images = {img['id']: img for img in coco.get('images', [])}\n",
    "    # cache loaded cv2 images\n",
    "    img_cache: dict = {}\n",
    "\n",
    "    for ann in coco.get('annotations', []):\n",
    "        bbox = ann.get('bbox', [])\n",
    "        if len(bbox) != 4:\n",
    "            logger.warning(f\"Skipping annotation {ann.get('id')} with unexpected bbox {bbox}\")\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = bbox\n",
    "        img_id = ann['image_id']\n",
    "        img_info = images.get(img_id)\n",
    "        if img_info is None:\n",
    "            logger.warning(f\"No image metadata for id {img_id}\")\n",
    "            continue\n",
    "\n",
    "        fname = img_info['file_name']\n",
    "        if fname not in img_cache:\n",
    "            img_path = IMAGES_DIR / fname\n",
    "            img = cv2.imread(str(img_path))\n",
    "            if img is None:\n",
    "                logger.error(f\"Failed to load image {img_path}\")\n",
    "                continue\n",
    "            img_cache[fname] = img\n",
    "\n",
    "        # crop & predict\n",
    "        patch = crop_box(img_cache[fname], x, y, w, h)\n",
    "        pred_angle = predict_angle(model, patch)\n",
    "        logger.debug(f\"Ann {ann['id']}: predicted {pred_angle}Â°\")\n",
    "\n",
    "        # update to OBB [cx, cy, w, h, angle]\n",
    "        cx = x + w/2\n",
    "        cy = y + h/2\n",
    "        ann['bbox'] = [cx, cy, w, h, float(pred_angle)]\n",
    "        # also store back into attributes.rotation\n",
    "        ann.setdefault('attributes', {})['rotation'] = float(pred_angle)\n",
    "\n",
    "    save_coco(coco, OUTPUT_JSON)\n",
    "    logger.info(\"All annotations updated with predicted rotations.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #update_rotations()\n",
    "    print(\"UNCOMMENT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr-rec-lab-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
