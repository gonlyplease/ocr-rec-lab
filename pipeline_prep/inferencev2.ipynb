{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69cf4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from typing import Tuple, List, Dict, Any\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.transforms import Affine2D\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "959f33d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Logging – enable *INFO* by default so that the user sees progress messages\n",
    "# -----------------------------------------------------------------------------\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(levelname)7s | %(name)s | %(message)s\")\n",
    "logger = logging.getLogger(\"rotation-pipeline\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configuration – adapt these paths to your project layout\n",
    "# -----------------------------------------------------------------------------\n",
    "COCO_JSON        = Path(\"../data/rotation/batches/rotation_20250721_01/annotations/instances_default.json\")\n",
    "IMAGES_DIR       = Path(\"../data/rotation/batches/rotation_20250721_01/images/default/\")\n",
    "PRED_JSON        = Path(\"../data/rotation/batches/rotation_20250721_01/instances_predicted.json\")\n",
    "ATTR_JSON        = Path(\"../data/rotation/batches/rotation_20250721_01/instances_updated.json\")\n",
    "CHECKPOINT_PATH  = Path(\"checkpoints/best_model.pth\")\n",
    "CSV_OUT          = Path(\"../data/rotation/batches/rotation_20250721_01/rot_summary.csv\")\n",
    "DEBUG_DIR        = Path(\"debug\")\n",
    "\n",
    "# Class labels *in the order used during training*\n",
    "CLASS_NAMES: List[int] = [0, 180, 270, 90]\n",
    "\n",
    "IMAGE_SIZE = 300\n",
    "\n",
    "# Device selection (GPU preferred)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93334868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# TorchVision preprocessing – identical to ImageNet‐trained ResNet18\n",
    "# -----------------------------------------------------------------------------\n",
    "TRANSFORM = transforms.Compose([\n",
    "    transforms.Resize((IMAGE, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93971de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IO helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_coco(path: Path) -> Dict[str, Any]:\n",
    "    logger.info(\"Loading COCO from %s\", path)\n",
    "    return json.loads(path.read_text(encoding=\"utf‑8\"))\n",
    "\n",
    "\n",
    "def save_coco(coco: Dict[str, Any], path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True,exist_ok=True)\n",
    "    logger.info(\"Writing COCO to %s\", path)\n",
    "    path.write_text(json.dumps(coco,ensure_ascii=False,indent=2), encoding=\"utf‑8\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Model loader\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_model(ckpt_path: Path) -> nn.Module:\n",
    "    \"\"\"Load the fine‑tuned ResNet18 classifier.\"\"\"\n",
    "    logger.info(\"Loading model from %s\", ckpt_path)\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(CLASS_NAMES))\n",
    "    ckpt = torch.load(str(ckpt_path), map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
    "    return model.to(DEVICE).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44d83da9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (4291106713.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    x1, y1 = max(0, int(round(x))), max(0, int(round(y)))\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "# Geometry helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def crop_box(img: np.ndarray, x: float, y: float, w: float, h: float) -> np.ndarray:\n",
    "    x1, y1 = max(0, int(round(x))), max(0, int(round(y)))\n",
    "    x2 = min(img.shape[1], int(round(x + w)))\n",
    "    y2 = min(img.shape[0], int(round(y + h)))\n",
    "    return img[y1:y2, x1:x2]\n",
    "\n",
    "\n",
    "def predict_angle(model: nn.Module, patch: np.ndarray, cur_rot: float) -> float:\n",
    "    \"\"\"Predict the *absolute* CW rotation of the object in *degrees*.\"\"\"\n",
    "    # Undo the current CW rotation so the patch is visually upright for the CNN.\n",
    "    h, w = patch.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), ‑cur_rot, 1.0)  # OpenCV wants CCW, hence –cur_rot\n",
    "    straight = cv2.warpAffine(patch, M, (w, h), borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "    rgb = cv2.cvtColor(straight, cv2.COLOR_BGR2RGB)\n",
    "    pil = Image.fromarray(rgb)\n",
    "    t = TRANSFORM(pil).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(t)\n",
    "        idx = int(torch.argmax(logits, dim=1).item())\n",
    "    return float(CLASS_NAMES[idx])\n",
    "\n",
    "\n",
    "def extract_current_rotation(ann: Dict[str, Any]) -> float:\n",
    "    \"\"\"Return the CW rotation (°) stored in the annotation – 0 if absent.\"\"\"\n",
    "    bb = ann.get(\"bbox\", [])\n",
    "    if len(bb) == 5:\n",
    "        return float(bb[4])\n",
    "    attrs = ann.get(\"attributes\", {})\n",
    "    return float(attrs.get(\"rotation\", 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac0c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug Utilities – optional visualisation helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def debug_annotation(ann_id: int, image_id: int, fname: str, orig_rot: float, pred_rot: float,\n",
    "                     bbox: List[float], full_img: np.ndarray, save_dir: Path | None = None):\n",
    "    \"\"\"Display or save side‑by‑side view of (crop, full image with overlays).\"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    patch = crop_box(full_img, x, y, w, h)\n",
    "\n",
    "    # Convert BGR → RGB for matplotlib\n",
    "    patch_rgb = cv2.cvtColor(patch, cv2.COLOR_BGR2RGB)\n",
    "    full_rgb = cv2.cvtColor(full_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    logger.debug(\"Annotation %s (%s): cur = %g°, pred = %g°\", ann_id, fname, orig_rot, pred_rot)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), dpi=150)\n",
    "    ax1.imshow(patch_rgb)\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.set_title(f\"Crop {patch.shape[1]}×{patch.shape[0]}\")\n",
    "\n",
    "    ax2.imshow(full_rgb)\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    # ----- Visual overlays ---------------------------------------------------\n",
    "    # Axis‑aligned bbox (orange dashed)\n",
    "    ax2.add_patch(Rectangle((x, y), w, h, fill=False, edgecolor=\"orange\", linestyle=\"--\"))\n",
    "\n",
    "    # Rotated bbox (red) – rotate **CCW** by *pred_rot* around centre (cx,cy)\n",
    "    cx, cy = x + w / 2, y + h / 2\n",
    "    obb = Rectangle((cx - w / 2, cy - h / 2), w, h, linewidth=1, edgecolor=\"red\", fill=False)\n",
    "    obb.set_transform(Affine2D().rotate_deg_around(cx, cy, pred_rot) + ax2.transData)\n",
    "    ax2.add_patch(obb)\n",
    "\n",
    "    # Anchor points\n",
    "    ax2.scatter([x], [y], color=\"blue\", s=5)\n",
    "    ax2.scatter([cx], [cy], color=\"lime\", s=5)\n",
    "    ax2.set_title(\"Full Image with boxes\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_dir is not None:\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        outfile = save_dir / f\"ann_{ann_id:05d}.png\"\n",
    "        fig.savefig(outfile, dpi=150)\n",
    "        plt.close(fig)\n",
    "        logger.debug(\"Saved debug image → %s\", outfile)\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa872f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core routine\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def update_rotations(target_image_id: int | None = None, debug: bool = False,\n",
    "                     save_csv: Path | None = None, save_debug_dir: Path | None = None) -> None:\n",
    "    \"\"\"Predict & update rotations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_image_id : int | None\n",
    "        If provided, restrict processing to this single *image_id* (handy during QA).\n",
    "    debug : bool\n",
    "        ``True`` → draw crops for every processed annotation.\n",
    "    save_csv : Path | None\n",
    "        If given, write summary DataFrame to this path (.csv).\n",
    "    save_debug_dir : Path | None\n",
    "        Directory that will receive one *PNG* per annotation when ``debug`` is *True*.\n",
    "    \"\"\"\n",
    "    coco_raw = load_coco(COCO_JSON)\n",
    "    coco_new = deepcopy(coco_raw)\n",
    "    model = load_model(CHECKPOINT_PATH)\n",
    "\n",
    "    # Cache full‑resolution images to avoid re‑loading on every annotation\n",
    "    images: Dict[int, Dict] = {img[\"id\"]: img for img in coco_raw[\"images\"]}\n",
    "    cache: Dict[str, np.ndarray] = {}\n",
    "    records: List[Dict] = []\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Pass 1 – iterate over annotations, predict angle, write back results\n",
    "    # ---------------------------------------------------------------------\n",
    "    for ann, ann_new in zip(coco_raw[\"annotations\"], coco_new[\"annotations\"]):\n",
    "        if target_image_id is not None and ann[\"image_id\"] != target_image_id:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = ann[\"bbox\"][:4]\n",
    "        cur_rot = extract_current_rotation(ann)\n",
    "\n",
    "        # Only evaluate if *cur_rot* is close to one of the discrete classes\n",
    "        if not any(abs(cur_rot - base) <= 10 for base in CLASS_NAMES):\n",
    "            continue\n",
    "\n",
    "        img_info = images[ann[\"image_id\"]]\n",
    "        fname = img_info[\"file_name\"]\n",
    "\n",
    "        if fname not in cache:\n",
    "            img = cv2.imread(str(IMAGES_DIR / fname))\n",
    "            if img is None:\n",
    "                logger.error(\"Could not load image %s\", fname)\n",
    "                continue\n",
    "            cache[fname] = img\n",
    "        img_full = cache[fname]\n",
    "\n",
    "        # ---------------- Prediction ----------------\n",
    "        crop = crop_box(img_full, x, y, w, h)\n",
    "        pred_rot = predict_angle(model, crop, cur_rot)\n",
    "\n",
    "        records.append({\n",
    "            \"ann_id\": ann[\"id\"],\n",
    "            \"img_id\": ann[\"image_id\"],\n",
    "            \"file_name\": fname,\n",
    "            \"bbox\": [x, y, w, h],\n",
    "            \"orig_rot\": cur_rot,\n",
    "            \"pred_rot\": pred_rot,\n",
    "        })\n",
    "\n",
    "        # Write back only if changed – avoid dirty diffs in repo\n",
    "        if pred_rot != cur_rot:\n",
    "            logger.info(\"Ann %5d: %3g° → %3g°\", ann[\"id\"], cur_rot, pred_rot)\n",
    "            cx, cy = x + w / 2, y + h / 2\n",
    "            ann_new[\"bbox\"] = [cx, cy, w, h, pred_rot]\n",
    "            ann_new.setdefault(\"attributes\", {})[\"rotation\"] = pred_rot\n",
    "\n",
    "        # Optional debug visualisation\n",
    "        if debug:\n",
    "            debug_annotation(ann[\"id\"], ann[\"image_id\"], fname, cur_rot, pred_rot,\n",
    "                             [x, y, w, h], img_full, save_dir=save_debug_dir)\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "    # Pass 2 – persist artifacts\n",
    "    # ---------------------------------------------------------------------\n",
    "    save_coco(coco_new, PRED_JSON)\n",
    "    save_coco(coco_new, ATTR_JSON)  # identical content, different file name for backwards compat\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    logger.info(\"Processed %s annotations\", len(df))\n",
    "\n",
    "    if save_csv is not None:\n",
    "        save_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(save_csv, index=False)\n",
    "        logger.info(\"Wrote CSV summary → %s\", save_csv)\n",
    "\n",
    "    if not df.empty:\n",
    "        logger.info(\"\\n%s\", df.head().to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e3c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image-id IMAGE_ID] [--debug]\n",
      "                             [--csv-out CSV_OUT] [--debug-dir DEBUG_DIR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/gerhardkarbeutz/Library/Jupyter/runtime/kernel-v36b67a94d2752417c2ae831325c4efa8870227c18.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerhardkarbeutz/cerpro/ocr-rec-lab/ocr-rec-lab-venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Command‑line Interface\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def _parse_args() -> argparse.Namespace:  # noqa: D401\n",
    "    \"\"\"CLI wrapper so you can run the script stand‑alone.\"\"\"\n",
    "    p = argparse.ArgumentParser(description=\"Rotation correction pipeline\")\n",
    "    p.add_argument(\"--image-id\", type=int, default=None,\n",
    "                   help=\"Process only this image_id (for debugging)\")\n",
    "    p.add_argument(\"--debug\", action=\"store_true\",\n",
    "                   help=\"Show / save per‑annotation debug panels\")\n",
    "    p.add_argument(\"--csv-out\", type=Path, default=CSV_OUT,\n",
    "                   help=\"Write summary CSV to this path\")\n",
    "    p.add_argument(\"--debug-dir\", type=Path, default=DEBUG_DIR,\n",
    "                   help=\"When --debug, save images here instead of showing them\")\n",
    "    return p.parse_args()\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    args = _parse_args()\n",
    "    update_rotations(target_image_id=args.image_id,\n",
    "                     debug=args.debug,\n",
    "                     save_csv=args.csv_out,\n",
    "                     save_debug_dir=args.debug_dir if args.debug else None)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocr-rec-lab-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
